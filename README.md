# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
This dataset contains data about individual banking information. We seek to predict whether or not, an individual would have their loan approved. The best performing model was a voting ensemble**

## Scikit-learn Pipeline
The first model trained was fitted using the following pipeline:

1. Load the data from a `.csv` using the `TabularDatasetFactory` class
2. Clean the data and proceed with variable encoding
3. Split the data into a `train` and `test` pandas dataframe
4. Proceed with a logistic regression (with the hyperparameter `C` (penalization parameter) optimized using a random search from the uniform distribution between 0 and 50)

The random search for hyperparameter tuning allows for a faster optimization. By experience, the gain from using other hyperparameter techniques for only 1 parameter is marginal. 

**What are the benefits of the early stopping policy you chose?**
By using the slack amount = 25%, I make sure that the accuracy improve significantly otherwise the run is canceled. That being said, I realise now that using a `evaluation_interval=2` was too greedy for a 25% increase in accuracy. I should have used a significantly larger parameter.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
AutoML generated different classification models. These were mostly gradient boosting methods. The more accurate model was a voting ensemble. Different normalization and imputation have been tested.

## Pipeline comparison
The voting ensemble from autoML was slightly more accurate (accuracy = 0.9149) compared to the hyperdrive's logistic regression (accuracy = 0.9121). The same data cleaning step has been applied to both models. However, autoML uses normalization and automated feature engineering and cross validation which are appreciable features.


## Future work
The following work could be done to enhance the hyperdrive model:
1. Switch the random search by a grid or bayesian search.
2. Try other models than logistic regressions
3. Proceed with more intelligent feature engineering
4. Optimize the max_total_run to test more hyperparameters


## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
